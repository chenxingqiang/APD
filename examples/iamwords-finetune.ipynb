{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cda29000b17cc0a",
   "metadata": {},
   "source": [
    "# Fine-tuning APD on IAM dataset\n",
    "This is an example of fine-tuning APD on IAM dataset handwritten words from [Kaggle](https://www.kaggle.com/datasets/teykaicong/iamondb-handwriting-dataset). IAM Aachen splits can be downloaded [here](https://www.openslr.org/56/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ce8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.patches as patches\n",
    "from torchvision import transforms\n",
    "from typing import Optional\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from albumentations import (\n",
    "    Compose, RandomBrightnessContrast, GaussNoise, ShiftScaleRotate, Blur\n",
    ")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from shapely.geometry import Polygon\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ensure the project root is in the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "if True:\n",
    "    from APD.config import APDConfig\n",
    "    from APD.processor import APDProcessor\n",
    "    from APD.model import APDModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672df8f4f58440b7",
   "metadata": {},
   "source": [
    "# Dataset folder structure\n",
    "```\n",
    "iam_words/\n",
    "│\n",
    "├── words/                              # Folder containing word images as PNGs\n",
    "│   ├── a01/                            # First folder\n",
    "│   │   ├── a01-000u/\n",
    "│   │   │   ├── a01-000u-00-00.png\n",
    "│   │   │   └── a01-000u-00-01.png\n",
    "│   │   .\n",
    "│   │   .\n",
    "│   │   .\n",
    "│   └── r06/                            # Last folder\n",
    "│       ├── r06-000/\n",
    "│       │   ├── r06-000-00-00.png\n",
    "│       │   └── r06-000-00-01.png\n",
    "│\n",
    "├── xml/                                # XML files\n",
    "│\t├── a01-000u.xml\n",
    "│\t.\n",
    "│\t.\n",
    "│\t.\n",
    "│\t└── r06-143.xml\n",
    "│\n",
    "└── splits/                             # IAM Aachen splits\n",
    "    ├── train.uttlist\n",
    "    ├── validation.uttlist\n",
    "    └── test.uttlist\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f83c2b6af325eb",
   "metadata": {},
   "source": [
    "# Build lists of images and texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6ad879545d49c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1539 XML files and 115320 word image files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class Word:\n",
    "    id: str\n",
    "    file_path: Path\n",
    "    writer_id: str\n",
    "    transcription: str\n",
    "\n",
    "dataset_path = Path('../datasets/iam_words')\n",
    "\n",
    "xml_files = sorted(glob.glob(str(dataset_path / 'xml' / '*.xml')))\n",
    "word_image_files = sorted(glob.glob(str(dataset_path / 'words' / '**' / '*.png'), recursive=True))\n",
    "\n",
    "print(f\"{len(xml_files)} XML files and {len(word_image_files)} word image files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3ffb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMDatasetForDBNet(Dataset):\n",
    "    def __init__(self, words: List[Word], config: APDConfig, is_training: bool = True):\n",
    "        self.words = words\n",
    "        self.config = config\n",
    "        self.is_training = is_training\n",
    "\n",
    "        if is_training:\n",
    "            self.augmenter = Compose([\n",
    "                RandomBrightnessContrast(p=0.5),\n",
    "                GaussNoise(p=0.3),\n",
    "                ShiftScaleRotate(p=0.5, rotate_limit=5),\n",
    "                Blur(p=0.3)\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words[idx]\n",
    "        image = Image.open(word.file_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Get normalized bounding box coordinates\n",
    "        h, w = image.shape[:2]\n",
    "        bbox = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)\n",
    "        bbox = bbox / np.array([w, h])[None, :]\n",
    "\n",
    "        if self.is_training and self.augmenter:\n",
    "            augmented = self.augmenter(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        # Resize image\n",
    "        image = cv2.resize(image, self.config.image_size[::-1])\n",
    "        image = torch.from_numpy(image).float() / 255.0\n",
    "        image = image.permute(2, 0, 1)\n",
    "\n",
    "        # Create targets\n",
    "        target = self._prepare_target(bbox, self.config.image_size)\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'prob_map': target['prob_map'],\n",
    "            'thresh_map': target['thresh_map'],\n",
    "            'binary_map': target['binary_map']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3012f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8abca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMDatasetForDBNet(Dataset):\n",
    "    def __init__(self, words: List[Word], config: APDConfig, is_training: bool = True):\n",
    "        self.words = words\n",
    "        self.config = config\n",
    "        self.is_training = is_training\n",
    "\n",
    "        if is_training:\n",
    "            self.augmenter = Compose([\n",
    "                RandomBrightnessContrast(p=0.5),\n",
    "                GaussNoise(p=0.3),\n",
    "                ShiftScaleRotate(p=0.5, rotate_limit=5),\n",
    "                Blur(p=0.3)\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words[idx]\n",
    "        image = Image.open(word.file_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Get normalized bounding box coordinates\n",
    "        h, w = image.shape[:2]\n",
    "        bbox = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)\n",
    "        bbox = bbox / np.array([w, h])[None, :]\n",
    "\n",
    "        if self.is_training and self.augmenter:\n",
    "            augmented = self.augmenter(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        # Resize image\n",
    "        image = cv2.resize(image, self.config.image_size[::-1])\n",
    "        image = torch.from_numpy(image).float() / 255.0\n",
    "        image = image.permute(2, 0, 1)\n",
    "\n",
    "        # Create targets\n",
    "        target = self._prepare_target(bbox, self.config.image_size)\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'prob_map': target['prob_map'],\n",
    "            'thresh_map': target['thresh_map'],\n",
    "            'binary_map': target['binary_map']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024e08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 替换原有的数据加载代码\n",
    "def generate_dataset(dataset_path: Path) -> Tuple[List[Word], List[Word], List[Word]]:\n",
    "    xml_files = sorted(glob.glob(str(dataset_path / 'xml' / '*.xml')))\n",
    "    word_image_files = sorted(\n",
    "        glob.glob(str(dataset_path / 'words' / '**' / '*.png'), recursive=True))\n",
    "    print(f\"{len(xml_files)} XML files and {len(word_image_files)} word image files\")\n",
    "\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        words_from_xmls = list(\n",
    "            tqdm.tqdm(\n",
    "                pool.imap(partial(get_words_from_xml,\n",
    "                          word_image_files=word_image_files), xml_files),\n",
    "                total=len(xml_files),\n",
    "                desc='Building dataset'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    words = [word for words in words_from_xmls for word in words]\n",
    "\n",
    "    # Load train/validation/test splits\n",
    "    with open(dataset_path / 'splits' / 'train.uttlist') as fp:\n",
    "        train_ids = set(line.strip() for line in fp)\n",
    "    with open(dataset_path / 'splits' / 'test.uttlist') as fp:\n",
    "        test_ids = set(line.strip() for line in fp)\n",
    "    with open(dataset_path / 'splits' / 'validation.uttlist') as fp:\n",
    "        validation_ids = set(line.strip() for line in fp)\n",
    "\n",
    "    train_words = [word for word in words if word.id in train_ids]\n",
    "    validation_words = [word for word in words if word.id in validation_ids]\n",
    "    test_words = [word for word in words if word.id in test_ids]\n",
    "\n",
    "    print(\n",
    "        f'Generated dataset - Train size: {len(train_words)}; Validation size: {len(validation_words)}; Test size: {len(test_words)}')\n",
    "    return train_words, validation_words, test_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea1601f0dabbde",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c924f758cc73a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6eb1ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed dataset from ../datasets/iam_words/processed_dataset.pkl\n",
      "Loaded dataset - Train size: 55079; Validation size: 8895; Test size: 25920\n",
      "Train size: 55079; Validation size: 8895; Test size: 25920\n"
     ]
    }
   ],
   "source": [
    "# First define all necessary functions\n",
    "def load_dataset(dataset_path: Path) -> Tuple[List[Word], List[Word], List[Word]]:\n",
    "    processed_file = dataset_path / 'processed_dataset.pkl'\n",
    "    if os.path.exists(processed_file):\n",
    "        print(f\"Loading processed dataset from {processed_file}\")\n",
    "        with open(processed_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        train_words = data['train_words']\n",
    "        validation_words = data['validation_words']\n",
    "        test_words = data['test_words']\n",
    "        print(\n",
    "            f'Loaded dataset - Train size: {len(train_words)}; Validation size: {len(validation_words)}; Test size: {len(test_words)}')\n",
    "    else:\n",
    "        print(\"Processed dataset not found. Generating new dataset.\")\n",
    "        train_words, validation_words, test_words = generate_dataset(\n",
    "            dataset_path)\n",
    "        save_dataset(dataset_path, train_words, validation_words, test_words)\n",
    "\n",
    "    return train_words, validation_words, test_words\n",
    "\n",
    "def save_dataset(dataset_path: Path, train_words: List[Word], validation_words: List[Word], test_words: List[Word]):\n",
    "    data = {\n",
    "        'train_words': train_words,\n",
    "        'validation_words': validation_words,\n",
    "        'test_words': test_words\n",
    "    }\n",
    "    with open(dataset_path / 'processed_dataset.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Dataset saved to {dataset_path / 'processed_dataset.pkl'}\")\n",
    "\n",
    "def generate_dataset(dataset_path: Path) -> Tuple[List[Word], List[Word], List[Word]]:\n",
    "    xml_files = sorted(glob.glob(str(dataset_path / 'xml' / '*.xml')))\n",
    "    word_image_files = sorted(\n",
    "        glob.glob(str(dataset_path / 'words' / '**' / '*.png'), recursive=True))\n",
    "    print(f\"{len(xml_files)} XML files and {len(word_image_files)} word image files\")\n",
    "\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        words_from_xmls = list(\n",
    "            tqdm.tqdm(\n",
    "                pool.imap(partial(get_words_from_xml,\n",
    "                          word_image_files=word_image_files), xml_files),\n",
    "                total=len(xml_files),\n",
    "                desc='Building dataset'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    words = [word for words in words_from_xmls for word in words]\n",
    "\n",
    "    # Load train/validation/test splits\n",
    "    with open(dataset_path / 'splits' / 'train.uttlist') as fp:\n",
    "        train_ids = set(line.strip() for line in fp)\n",
    "    with open(dataset_path / 'splits' / 'test.uttlist') as fp:\n",
    "        test_ids = set(line.strip() for line in fp)\n",
    "    with open(dataset_path / 'splits' / 'validation.uttlist') as fp:\n",
    "        validation_ids = set(line.strip() for line in fp)\n",
    "\n",
    "    train_words = [word for word in words if word.id in train_ids]\n",
    "    validation_words = [word for word in words if word.id in validation_ids]\n",
    "    test_words = [word for word in words if word.id in test_ids]\n",
    "\n",
    "    print(\n",
    "        f'Generated dataset - Train size: {len(train_words)}; Validation size: {len(validation_words)}; Test size: {len(test_words)}')\n",
    "    return train_words, validation_words, test_words\n",
    "\n",
    "# Then use the functions\n",
    "dataset_path = Path('../datasets/iam_words')\n",
    "\n",
    "# Load or generate dataset\n",
    "train_words, validation_words, test_words = load_dataset(dataset_path)\n",
    "\n",
    "# Create datasets\n",
    "config = APDConfig()\n",
    "train_dataset = IAMDatasetForDBNet(train_words, config, is_training=True)\n",
    "val_dataset = IAMDatasetForDBNet(validation_words, config, is_training=False)\n",
    "test_dataset = IAMDatasetForDBNet(test_words, config, is_training=False)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
    "                         shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n",
    "                       shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
    "                        shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}; Validation size: {len(val_dataset)}; Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449f0ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed dataset from ../datasets/iam_words/processed_dataset.pkl\n",
      "Loaded dataset - Train size: 55079; Validation size: 8895; Test size: 25920\n",
      "Train size: 55079; Validation size: 8895; Test size: 25920\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare dataset\n",
    "dataset_path = Path('../datasets/iam_words')\n",
    "\n",
    "# Load or generate dataset\n",
    "train_words, validation_words, test_words = load_dataset(dataset_path)\n",
    "\n",
    "def load_dataset(dataset_path: Path) -> Tuple[List[Word], List[Word], List[Word]]:\n",
    "    processed_file = dataset_path / 'processed_dataset.pkl'\n",
    "    if os.path.exists(processed_file):\n",
    "        print(f\"Loading processed dataset from {processed_file}\")\n",
    "        with open(processed_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        train_words = data['train_words']\n",
    "        validation_words = data['validation_words']\n",
    "        test_words = data['test_words']\n",
    "        print(\n",
    "            f'Loaded dataset - Train size: {len(train_words)}; Validation size: {len(validation_words)}; Test size: {len(test_words)}')\n",
    "    else:\n",
    "        print(\"Processed dataset not found. Generating new dataset.\")\n",
    "        train_words, validation_words, test_words = generate_dataset(\n",
    "            dataset_path)\n",
    "        save_dataset(dataset_path, train_words, validation_words, test_words)\n",
    "\n",
    "    return train_words, validation_words, test_words\n",
    "\n",
    "def save_dataset(dataset_path: Path, train_words: List[Word], validation_words: List[Word], test_words: List[Word]):\n",
    "    data = {\n",
    "        'train_words': train_words,\n",
    "        'validation_words': validation_words,\n",
    "        'test_words': test_words\n",
    "    }\n",
    "    with open(dataset_path / 'processed_dataset.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Dataset saved to {dataset_path / 'processed_dataset.pkl'}\")\n",
    "\n",
    "# Create datasets\n",
    "config = APDConfig()\n",
    "train_dataset = IAMDatasetForDBNet(train_words, config, is_training=True)\n",
    "val_dataset = IAMDatasetForDBNet(validation_words, config, is_training=False)\n",
    "test_dataset = IAMDatasetForDBNet(test_words, config, is_training=False)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, \n",
    "                         shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, \n",
    "                       shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, \n",
    "                        shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}; Validation size: {len(val_dataset)}; Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d6d01cac2ef35",
   "metadata": {},
   "source": [
    "# Build dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460aa9a2caa3af6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18096c11905a980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from APD.dbnet import DBNet  # 确保路径正确\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# 替代方案：使用 torchvision 的 ResNet\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "backbone = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "\n",
    "# 使用 DBNet\n",
    "\n",
    "# 创建模型实例\n",
    "# Check if MPS is available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model instance\n",
    "model = DBNet(backbone_name='resnet18')\n",
    "model = torch.compile(model)\n",
    "model.to(device)  # Use the detected device instead of hardcoding to CUDA\n",
    "\n",
    "\n",
    "def test_model(model, test_dataset, processor):\n",
    "    model.eval()\n",
    "    for test_word in test_dataset[:5]:  # 测试前5个样本\n",
    "        image = Image.open(test_word.file_path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # 预处理图像\n",
    "        preprocessed = processor.preprocess_image(image_np)\n",
    "\n",
    "        # 模型推理\n",
    "        with torch.no_grad():\n",
    "            outputs = model(preprocessed.unsqueeze(0).to(model.device))\n",
    "\n",
    "        # 后处理结果\n",
    "        regions = processor.postprocess(outputs, image_np.shape[:2])\n",
    "\n",
    "        # 可视化结果\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(image_np)\n",
    "        for region in regions:\n",
    "            bbox = region['bbox']\n",
    "            plt.plot(bbox[:, 0], bbox[:, 1], 'r-', linewidth=2)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10a9feb1801174",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8257602fcea271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zv/xnstggzd6rsdrc5xk2bcfhn40000gn/T/ipykernel_59731/2263816881.py:44: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "Epoch 1:   0%|          | 0/1722 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 120, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py\", line 130, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'IAMDatasetForDBNet' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "def evaluate_model(model: torch.nn.Module, dataloader: DataLoader) -> Tuple[float, float]:\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    losses, accuracies = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm.tqdm(dataloader, total=len(dataloader), desc=f'Evaluating test set'):\n",
    "            inputs = send_inputs_to_device(inputs, device=0)\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            losses.append(outputs.loss.item())\n",
    "            accuracies.append(outputs.accuracy.item())\n",
    "\n",
    "    loss = sum(losses) / len(losses)\n",
    "    accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "    # set model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def send_inputs_to_device(dictionary, device):\n",
    "    return {key: value.to(device=device) if isinstance(value, torch.Tensor) else value for key, value in dictionary.items()}\n",
    "\n",
    "\n",
    "use_amp = True\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "optimiser = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "\n",
    "EPOCHS = 50\n",
    "train_losses, train_accuracies = [], []\n",
    "validation_losses, validation_accuracies = [], []\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_losses, epoch_accuracies = [], []\n",
    "    for inputs in tqdm.tqdm(train_loader, total=len(train_loader), desc=f'Epoch {epoch + 1}'):\n",
    "\n",
    "        # set gradients to zero\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # send inputs to same device as model\n",
    "        inputs = send_inputs_to_device(inputs, device=0)\n",
    "\n",
    "        # forward pass\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # calculate gradients\n",
    "        scaler.scale(outputs.loss).backward()\n",
    "\n",
    "        # update weights\n",
    "        scaler.step(optimiser)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_losses.append(outputs.loss.item())\n",
    "        epoch_accuracies.append(outputs.accuracy.item())\n",
    "\n",
    "    # store loss and metrics\n",
    "    train_losses.append(sum(epoch_losses) / len(epoch_losses))\n",
    "    train_accuracies.append(sum(epoch_accuracies) / len(epoch_accuracies))\n",
    "\n",
    "    # tests loss and accuracy\n",
    "    # tests loss and accuracy\n",
    "    validation_loss, validation_accuracy = evaluate_model(model, val_loader)\n",
    "    validation_losses.append(validation_loss)\n",
    "    validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1} - Train loss: {train_losses[-1]}, Train accuracy: {train_accuracies[-1]}, Validation loss: {validation_losses[-1]}, Validation accuracy: {validation_accuracies[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399ad87bbfd16da",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d7fd369dee5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from APD.model import APDLMHeadModel\n",
    "from APD.config import APDConfig\n",
    "from APD.processor import APDProcessor\n",
    "\n",
    "# model = APDLMHeadModel(APDConfig())\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "test_processor = APDProcessor(APDConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e815a0557072e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "for test_word_record in test_word_records[:50]:\n",
    "    image_file = test_word_record.file_path\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "\n",
    "    inputs = test_processor(\n",
    "        images=image,\n",
    "        texts=test_processor.tokeniser.bos_token,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    model_output = model.generate(\n",
    "        inputs,\n",
    "        test_processor,\n",
    "        num_beams=3\n",
    "    )\n",
    "\n",
    "    predicted_text = test_processor.tokeniser.decode(model_output[0], skip_special_tokens=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(predicted_text, fontsize=24)\n",
    "    plt.imshow(np.array(image, dtype=np.uint8))\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
